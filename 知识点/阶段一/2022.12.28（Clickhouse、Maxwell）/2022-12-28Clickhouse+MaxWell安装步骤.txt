
jdk
hadoop完全分布式
hive单机
spark
flink
hbase
flume
kafka
zookeeper

clickhouse（数据库）

maxwell（安装）
redis（安装、简单的使用）


1、Clickhouse安装
     1）解压4个clickhouse安装包到指定目录
          tar -zxvf clickhouse-common-static-21.9.4.35.tgz -C /usr/local/src/clickhouse/
	tar -zxvf clickhouse-common-static-dbg-21.9.4.35.tgz -C /usr/local/src/clickhouse/
	tar -zxvf clickhouse-client-21.9.4.35.tgz -C /usr/local/src/clickhouse/
	tar -zxvf clickhouse-server-21.9.4.35.tgz -C /usr/local/src/clickhouse/
     2）进入各个目录下执行 /install/doinst.sh 执行该文件（顺序可以不管）
	clickhouse-common-static-21.9.4.35/install/doinst.sh
	clickhouse-common-static-dbg-21.9.4.35/install/doinst.sh
	clickhouse-client-21.9.4.35/install/doinst.sh
	clickhouse-server-21.9.4.35/install/doinst.sh
	其中安装clickhouse-server的时候会提示输入默认账户user的密码，和是否允许远程访问。

     3）修改安装之后相关目录的所有权给root账户：
	chown -R root:root /var/lib/clickhouse/ /var/log/clickhouse-server/ /etc/clickhouse-server/ /etc/clickhouse-client/
     4）修改配置文件：vim /etc/clickhouse-server/config.xml
	1》修改远程访问
		<!-- <listen_host>::</listen_host> -->
		将注释去掉才能让除本机外的clickhouse访问
	2》修改时区
		找到timezone标签，将内容修改为Asia/Shanghai
	3》修改9000端口（因为9000被hadoop给占用了）
		<tcp_port>9002</tcp_port>
		【注意：上面的9002为示例，也可以是9001】
		【注意：最好将相关的9000端口全部给改成9002】 
     5）启动clickhouse
         1》正常启动会占用终端
	clickhouse-server --config-file=/etc/clickhouse-server/config.xml
	2》后台启动：
	clickhouse-server --config-file=/etc/clickhouse-server/config.xml >null 2>&1 &
	【启动之后可以通过netstat -tnulp命令查看9002端口和8123端口占用情况是否正常】
	netstat -tnulp | grep clickhouse
     6）连接clickhouse
	clickhouse-client --port 9002 -u default --password 123456
	【如果是远程连接其他机器上的clickhouse，可以加入参数 -h 192.168.xx.xxx】
    
     7）使用clickhouse
          1》创建数据库：create database mytest;
	2》定位数据库：use mytest;
	3》创建表（指定表的引擎）
		引擎类别：
		1>>> TinyLog		
			TinyLog表引擎是以列文件的形式保存在磁盘上，不支持索引，并且没有并发控制。一般适用于保存少量数据的小表。
		2>>> Memory
			 Memory是一种内存引擎，数据会以未压缩的原始形式直接保存在内存当中，服务器重启数据就会消失，对于读写操作不会相互阻塞，但是不支持索引。简单查询下有非常高的性能表现(超过10G/s)。一般用到它的地方不多，除了用来测试，就是在需要非常高的性能，同时数据量又不大 (上限大概1亿行) 的场景。

		3>>> MergeTree
			ClickHouse 中最强大的表引擎当属MergeTree(合并树) 引擎及该系列( *MergeTree ) 中的其他引擎，它支持索引和分区，地位可以相当于innodb 之于Mysql。而且基于MergeTree，还衍生出了很多子引擎，是一个非常有特色的表引擎。
		4>>> ReplacingMergeTree	
			 ReplacingMergeTree 是 MergeTree 的一个变种，它存储特性完全继承 MergeTree，只是多了一个去重的功能。 尽管 MergeTree 可以设置主键，但是 primary key 其实没有唯一约束的功能。如果你想处理掉重复的数据，可以借助这个 ReplacingMergeTree。
	
		5>>> SummingMergeTree
			对于不查询明细，只关心以维度进行汇总聚合结果的场景。如果只使用普通的MergeTree的话，无论是存储空间的开销，还是查询时临时聚合的开销都比较大。ClickHouse 为了这种场景，提供了一种能够“预聚合”的引擎 SummingMergeTree。我们在设计聚合表的时候，可以将唯一键值、流水号去掉，所有字段全部是维度、度量或者时间戳。
	
	建表语法：
		create table 表名(列名 类型,列名 类型,...)
		ENGINE = MergeTree()
		ORDER BY cityname
例如：
CREATE TABLE tb_student
(
    `sid` int,
    `sname` String,
    `birthday` date,
    `phone` String,
    `sex` String
)
ENGINE = MergeTree
ORDER BY sid

	查看表结构：
	desc tb_student;
	
  
   3、maxwell监控mysql的变化
        1》maxwell可以用于监控mysql中表数据的变化，然后收集起来，发送给其他平台如（kafka等）
        2》在mysql的配置文件  /etc/my.cnf中加入下列内容
             #mysql binlog开启
原来配置的：
[mysqld]
datadir=/usr/local/src/mysql5.7/data
port=3306
sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES
symbolic-links=0
max_connections=400
innodb_file_per_table=1
#表名大小写不明感，敏感为
lower_case_table_names=1
#新加入的：
server-id=1
log-bin=mysql-bin
binlog_format=row
binlog-do-db=shtd_db1

          【注意：修改mysql的主配置文件后，要重启mysql，否则不生效】
           service mysql restart
      3》解压maxwell到指定的目录：
           tar -zxvf maxwell-1.29.0.tar.gz -C /usr/local/src/
           cd /usr/local/src/
           mv maxwell-1.29.0/ maxwell
          【环境变量自己选配】
            vim /root/.bash_profile
	 
            export MAXWELL_HOME=/usr/local/src/maxwell
	  export PATH=$PATH:$MAXWELL_HOME/bin

            source /root/.bash_profile
       4》修改maxwell的配置文件：
            cp config.properties.example config.properties
            vim config.properties

          producer=kafka
	kafka.bootstrap.servers=bigdata1:9092,bigdata2:9092,bigdata3:9092
	kafka_topic=shtd_db1

	host=localhost
	user=root
	password=123456
        5》启动maxwell之前需要启动zookeeper、kafka集群，然后在kafka中创建主题：shtd_db1
             kafka-topics.sh --create --zookeeper bigdata1:2181 --replication-factor 1 --partitions 1 --topic shtd_db1

	kafka-console-consumer.sh --bootstrap-server bigdata3:9092 --topic shtd_db1 --from-beginning

       6》启动maxwell（进入maxwell的bin目录，然后执行）
            ./maxwell --config /usr/local/src/maxwell/config.properties
            
       【常见错误：启动maxwell的时候如果报server_id is '0'.，将mysql的配置文件 /etc/my.cnf复制到/usr/local/src/mysql5.7/下，再不行，data目录下也放一个，重启mysql】

		