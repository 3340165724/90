## 阶段一环境配置

### 前置准备

```
1.修改主机名
	1.vi /etc/hostname
	2.hostnamectl set-hostname 主机名
	3.ctrl + D
	
2.配置hosts
	1.vi /etc/hosts
	ip+master
	ip+slave1
	ip+slave2
	
3.关闭防火墙
	1.查看防火墙状态
		systemctl status firewalld
	2.关闭防火墙
		systemctl stop firewalld
	3.开启开机自动关闭防火墙
		systemctl disable firewalld
	4.配置 /etc/selinux/confg 
		enconfig = disabled
		
4.配置ssh
	1.生成公钥
		ssh-keygen -t rsa
	2.copy公钥到其他节点
		ssh-copy-d master /slave1/slave2
	3.测试免密是否成功
		ssh master/slave1/slave2

5.查看是否自带jdk
	rpm -qa | grep java
```



### 一、配置JDK

```
1. 环境变量
export JAVA_HOME=/usr/local/src/jdk
export PATH=$PATH:$JAVA_HOME/bin

2.测试版本
java  -version
javac -version

3.刷新配置文件
source /root/base_profile
```



### 二、配置HADOOP

```xml
1.环境变量
export HADOOP_HOME=/usr/local/src/hadoop
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin

2.配置core-site.xml
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://master:9000</value>
</property>

<property>
    <name>hadoop.tmp.dir</name>
    <value>/opt/data/hadoop</value>
</property>

3.配置dfs-site.xml
<property>
    <name>hdfs.replication</name>
    <value>3</value>
</property>

4.配置mapduce-site.xml
<property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
</property>

5.配置yarn-site.xml
<property>
    <name>yarn.resourcemanager.hostname</name>
    <value>master</value>
</property>

<property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
</property>

<property>
    <name>yarn.nodemanager.vmem-check-enabled</name>
    <value>false</value>
</property>

<property>
    <name>yarn.nodemanager.pmem-check-enabled</name>
    <value>false</value>
</property>

6.配置workes
master
slave1
salve2

7.copy hadoop 到从节点
 scp -r /usr/local/src/hadoop slave1:/usr/local/src
 scp -r /usr/local/src/hadoop slave2:/usr/local/src

8.格式化hadoop
 hdfs namenode -format

9.jps 查看节点
DATANODE
NAMENODE
SECONDARYNAMENODE
resourcemanager
nodemanager
```



### 三、配置SPARK

```
1.配置环境变量
export SPARK_HOME=/usr/local/src/spark
export PATH=$PATH:$SPARK_HOME/sbin:$SPARK_HOME/bin

2.刷新soure
source /root/bash_profile

3.配置spark.env.sh
export JAVA_HOME=/usr/local/src/jdk
export HADOOP_CONF_DIR=/usr/local/src/hadoop/etc/hadoop
export SPARK_CONF_DIR=/usr/local/src/spark/conf
export SPARK_MASTER_HOST=master/local/127.0.0.1
export SPARK_MASTER_PORT=7077

4.配置workes
master
slave1
slave2

5.copy spark 到从节点
 scp -r /usr/local/src/hadoop slave1:/usr/local/src
 scp -r /usr/local/src/hadoop slave2:/usr/local/src

6.启动spark 案例
 集群的方式
 spark-submit --class org.apache.spark.example.SparkPi jar…… 100

```



### 四、配置FLINK -- 需要先关闭spark 端口占用

```
1. 配置环境变量
export FLINK_HOME=/usr/local/src/flink
export PATH=$PATH:$FLINK_HOME/bin

2.配置flink.conf.yaml
address: master 

3.配置workers
master
slave1
slave2

4.copy spark 到从节点
 scp -r /usr/local/src/hadoop slave1:/usr/local/src
 scp -r /usr/local/src/hadoop slave2:/usr/local/src
 
5.启动 flink 集群案例
flink run WordCount.jar 
```



### 五、配置HIVE

```xml
1. 配置环境变量
export HIVE_HOME=/usr/local/src/hive
export PATH=$PATH:$HIVE_HOME/bin

2.配置 hive-site.xml
1. touch hive-site.xml  然后把 hive-default.xml.template 的标头copy 过来

<property>
	<name>javax.jdo.option.ConnectionUserName</name>
    <value>root</value>
</property>

<property>
	<name>javax.jdo.option.ConnectionPassword</name>
    <value>123456</value>
</property>

<property>
	<name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&amp;useSSL=false&amp;characterEncoding=UTF-8</value>
</property>

<property>
	<name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
</property>

2. 删除 log4h-slf4j.jar
rm -rf log4j-slf4j-impl-2.10.0.jar

3.删除guava
rm -rf guava

4.copy hadoop 的guava 到hive的lib 目录下
cp /usr/local/src/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar  /usr/local/src/hive/lib/

5.copy mysql5.7 jar 到lib 目录下

6.初始化hive元数据
schematool -dbType mysql --Schema

```



### 六、配置ZOOKEEPER

```
1.配置环境变量
export ZOOKEEPER_HOME=/usr/local/src/zookeeper
export PATH=$PATH:$ZOOKEEPER_HOME/bin

2.配置 zoo.cfg
cp  zoo_sample.cfg zoo.cfg

dataDir=/usr/local/src/zookeeper/data
server.1=master:2888:3888
server.2=slave1:2888:3888
server.3=slave2:2888:3888

3.配置 /data/myid
在 conf 同级别目录下 新建 data / myid 
master : 1
slave1 : 2
slave2 : 3

4.zookeeper 分发到从节点
scp -r /usr/local/src/zookeeper slave1:/usr/local/src/
scp -r /usr/local/src/zookeeper slave2:/usr/local/src/

5.启动zookeeper 并且查看状态
zkServer.sh start  启动
zkServer.sh status 查看状态
zkServer.sh stoop 关闭zookeeper
```



### 七、配置KAFKA -- 阶段四重点

```
1. 配置环境变量
export KAFKA_HOME=/usr/local/src/kafka
export PATH=$PATH:$=KAFAK_HOME/bin

2.配置server.property
broker.id = 1
hostname=master
listeners = PLAINTEXT://0.0.0.0:9092
advertised.host.name=192.168.43.191
advertised.listeners=PLAINTEXT://192.168.43.191:9092

logs
logs=/usr/local/src/kafka/logs

zookeeper
master:2181,salve1:2181,salve2:2181


1.查看kafka主题
	kafka-topic.sh --list --zookeeper master:2181
2.创建kafka主题
	kafka-topic.sh --create --zookeeper maser:2181 --replication-factor 1 --partitions --topic zhang
3.开启生产者 -- produce
	kafka-console.produce.sh --broker-list master:9092 --topic zhang
4.开启消费者 -- consumer
	kafka-console.consumer.sh bootstrap-server maste:9092 --form-beginning 

```



###  八、配置FLUME

```
1.配置环境变量
export FLUME_HOME=/usr/local/src/flume
export PATH=$PATH:$FLUME_HOME/bin

2. 配置数据 来自端口 打印到控制台
    vi duankou.conf
    a1.sources=r1
    a1.channels=c1
    a1.sinks=k1

    a1.sources.r1.type=netcat
    a1.sources.r1.bind=master
    a1.sources.r1.port=12000

    a1.channels.c1.type=memory

    a1.sinks.k1.type=logger

    a1.sources.r1.channels=c1
    a1.sinks.k1.channel=c1
    
 结果打印到kafka
 a1.sources=r1
 a1.channels=c1
 a1.sinks=k1
 
 a1.sources.k1.type=netcat
 a1.sources.k1.bind=master
 a1.sources.k1.port=12000
 
 a1.channels.c1.type=memory
 
 数据打印到kafka
 a1.sinks.k1.type=org.apache.flume.sink.kafka.KafkaSink
 a1.sinks.k1.brokerList=mster:9092,slave1:9092,slave2:9092
 a1.sinks.k1.topic=zhang
 
 a1.sources.r1.channels=c1
 a1.sinks.k1.channel=c1
 
 启动flume
flume-ng agent -c conf -f /usr/local/src/flume/conf/文件名.conf --name a1 -Dflume.root.logger=INFO,console
```



### 九、配置HBASE -- 集群

```xml
1. 环境变量
export HBASE_HOME=/usr/local/src/hbase
export PATH=$PATH:$HBASE_HOME/bin

2.配置hbase-env.sh 文件
 1.修改jdk路径
	JAVA_HOME=/usr/local/src/jdk
 2.修改自带ZOOKEEPER
	HBASE_MANAGES_ZK=false

3.配置hbase-site.xml
使用外部hbase
<property>
	<name>hbase.cluster.distrbuted</name>
    <value>true</value>
</property>

确定使用的ZOOKEEPER
<property>
	<name>hbase.zookeper.quorum</name>
    <value>master1,slave1,slave2</value>
</property>

hbase存放hadoop的目录
<property>
	<name>hbase.rootdir</name>
    <value>hdfs://master:9000/hbase</value>
</property>

关闭hbase安全模式
<property>
	<name>hbase.unsafe.stream.capability.enforce</name>
    <value>false</value>
</property>

4.节点分发
 scp -r /usr/local/src/hbase slave1:/usr/local/src/
 scp -r /usr/local/src/hbase slave2:/usr/local/src/

5.启动hbase  bin
./start-hbase.sh 

6.进入hbase
hbase shell

```



### 十、配置MAXWELL -- 单机

```
1.配置环境变量
export MAXWELL_HOME=/usr/local/src/maxwell
export PATH=$PATH:$MAXWELL_HOME/bin

2.在 /etc/my.cnf 配置文件中添加以下内容：
    1.数据库id
    server-id=随便写

    2.启动binlog
    log-bin=mysql-bin

    3.设置binlog类型为row
    binlog_foramt=row

    4.设置需要监控的数据库名称
    binlog-do-db=数据库名称 -- 数据库必须存在


3.修改配置文件 config.properties
    produce=kafka
    kafka.bootstrap.server=master,slave1,slave2

    设置主题名 == 该行需要自行添加
    kafka_topic=主题名 -- 必须是存在的主题名

    #登录数据库的用户名和密码
    host=localhost/主机名/root
    user=root
    password=数据库密码

4.启动maxwell
maxwell -config  /usr/local/src/maxwell/config.properties -daemon
```



### 十一、配置ClickHouse 单机

```
clickhous 可以不用配置环境变量

2.	解压4个clickhouse安装包到指定位置
	tar -zxvf clickhouse-common-static-21.9.4.35.tgz -C /usr/local/src/clickhouse/
	tar -zxvf clickhouse-common-static-dbg-21.9.4.35.tgz -C /usr/local/src/clickhouse/
	tar -zxvf clickhouse-client-21.9.4.35.tgz -C /usr/local/src/clickhouse/
	tar -zxvf clickhouse-server-21.9.4.35.tgz -C /usr/local/src/clickhouse/
	
3.进入各个目录下 执行/install/doinst.sh  -- 可以不用管执行顺序
	clickhouse-common-static-21.9.4.35/install/doinst.sh
	clickhouse-common-static-dbg-21.9.4.35/install/doinst.sh
	clickhouse-client-21.9.4.35/install/doinst.sh
	clickhouse-server-21.9.4.35/install/doinst.sh
	在安装clickhouse-server的时候会提示输入默认账户的user密码和是否运行远程访问
	
4.修改安装之后给相关目录的所有权给到root用户
	chown  -R root:root /var/lib/clickhouse /var/log/clickhouse-server /etc/clickhouse-server /etc/clickhouse-client
	
5.	修改配置文件：/etc/clickhouse-server/config.xml
	(1). 修改远程访问
			<!-- <listen_host>::</listen_host> -->
			将注释去掉才能让除本机外的clickhouse访问
			
	(2). 修改时区
    		找到timezone标签，将内容修改为Asia/Shanghai
    		
    (3). 修改9000端口 9000端口被hadoop占用
    		<tcp_port>9002</tcp_port>
    		
6.	启动clickhouse客户端
	clickhouse-server --config-file=/etc/clickhouse-server/config.xml
	启动之后可以使用netstat -tnulp | grep clickhouse 查看端口的占用情况
	
7.	连接clickhouse
	clickhouse-client --port 9002 -u default --password 123 
	如果使用远程连接加入参数既可：-h 192.168.XX.XX
	
```

