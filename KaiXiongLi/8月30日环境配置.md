### 环境配置

#### 配置技巧

```
1.查看试卷 是不是所有的jar包都解压到同一个位置
	如果是则可由把有关联的jar同时解压  如：jdk hadoop  spark
	如果不是就一个一个解压
2.hadoop中需要用到jdk的路径
3.spark中需要用到jdk hadoop的路径
```



##### 一、JDK 配置

```
1. 配置环境变量
	export JAVA_HOME=/opt/module/复制粘贴
	export PATH=$PAHT:$JAVA_HOME/bin
	
2.source 环境变量
	source /etc/profile

3.查看是否生效
	java  -version
	javac -version
```

##### 二、HADOOP 集群配置

```xml
1.配置环境变量
	export HADOOP_HOME=/opt/module/ -- 文本复制粘贴
	export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
	
2.source 环境变量
	source /etc/profile

3.查看版本信息
	hadoop version

4.配置hanoop-env.sh
	export HDFS_NAMENODE_USER=root
	export HDFS_DATANODE_USER=root
	export HDFS_CECONDARYNAMENODE_USER=root
	export YARN_RESOURCEMANAGER_USER=root
	export YARB_NODEMANAGER_USER=root

5.配置core-site.xml
	<property>
		<name>fs.defaultFS</name>
        <value>hdfs://master:9000</value>
	</property>

	<property>
		<name>hadoop.tmp.dir</name>
        <value>/hadoop/opt/data</value>
	</property>

6.配置hdfs.site.xml
	<property>
		<name>dfs.replicatino</name>
        <value>3</value>
	</property>

7.配置mapred-site.xml
	<property>
		<name>mapreduce.framework.name</name>
        <value>yarn</value>
	</property>

8.配置yarn-site.xml
	<property>
		<name>yarn.resourcemanager.hostname</name>
        <value>mastet</value>
	</property>

	<property>
		<name>yarn.nodemanaget.aux-services</name>
        <value>mapreduce_shuffle</value>
	</property>

	<property>
		<name>yarn.nodemanager.pmem-check-enabled</name>
        <value>false</value>
	</property>

	<property>
		<name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
	</property>

9.配置works
	master
	slave1
	slave2

10.节点分发
	scp -r /opt/module/hadoop slave1:/opt/module
	scp -r /opt/module/hadoop slave2:/opt/module

11.格式化hadooop
	hdfs namenode -format 
	
12.启动hdf,yarn
	./start.hdfs.sh
	./start.yarn.sh
```



##### 三、SPARK集群配置

```
1.环境变量
	export SPARK_HOME=/opt/module/ --文本复制粘贴
	export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
	
2.source 环境变量
	source /etc/profile

3.查看spark版本号
	spark-submit version
	
4.配置spark-env.sh  cp spark-env.sh-templates spark-env.sh
	export JAVA_HOME=/opt/module/  --文本复制粘贴
	export HADOOP_CONF_DIR=/opt/module/hadoop(文本复制粘贴)/etc/hadoop
	export SPARK_CONF_DIR=/opt/module/spark(文本复制粘贴)/conf
	export SPARK_MASTER_HOST=master | ip
	export SPARK_MASTER_PORT=7077
	
5.配置workes 
	master
	slave1
	slave2
	
6.source 环境变量
	source /etc/profile

7.节点分发
	scp -r /opt/module/spark slave1:/opt/module
	scp -r /opt/module/spark slave1:/opt/module
	
8.启动spark
	./start-all.sh

9.节点明细
	master
	work
	
10.spark 案例 集群案例 | yarn案例
	集群案例：
		spark-submit --class org.apache.spark.examples.SparkPi spark……jar 100
	yarn案例：
		spark-submit --class org.apache.spark.examples.SparkPi --master yarn spark……jar 100
```



##### 四、FLINK集群配置

```
1.配置环境变量
	export FLINK_HOME=/opt/module/ -- 文本复制
	export PATH=$PATH:$FLINK_HOME/bin

2.source 环境变量
	source /etc/profile
	
3.配置flik.yan.xml
	找到 addr= localhost 改为 master | ip

4.配置works
	master
	slave1
	slave2

5.节点分发
	scp -r /opt/module/flik slave1:/opt/module/
	scp -r /opt/module/flik slave2:/opt/module/
	
6.启动flink
	flink-cluster.sh

7.flink案例
	flink run WOrdCount.txt  这样必须在相对路径下执行才有效 否则得加绝地路径
```

##### 五、HIVE配置

```xml
1.配置环境变量
	export HIVE_HOME=/opt/module/  -- 文本copy
	export PATH=$PATH:$HIVE_HOME/bin

2.source 环境变量
	source /etc/profile

3.配置hive-site.xml
	<property>
		<name>javax.jdo.option.ConnectionUserName</name>
        <value>root</value>
	</property>

	<property>
		<name>javax.jdo.option.ConnectionPassword</name>
        <value>123456</value>
	</property>

	<property>
		<name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&amp;useSSL=false&amp;characterEncoding=utf-8</value>
	</property>

	<property>
		<name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
	</property>

4.删除log4j-slf4j ……

5.删除guava17.jar

6.copy mysql-connection …… jar 到 hive的libe目录下

7.copy hadoop lib 目录下的guava27.jar 到hive 的lib目录下

8.初始化hive元数据
	schematool -dbType mysql -initSchema
```

##### 六、配置zookeeper 集群

```
1.环境变量
	export ZOOKEEPER_HOME=/opt/module/zookeeper
	export PATH=$PATH:$ZOOKEEPER_HOME/bin
	
2.配置zoo.cfg  cp zoo.template.cfg zoo.cfg
	datadir=/opt/module/zookeeper/data
	server.1=master:2888:3888
	server.2=slave1:2888:3888
	server.3=slave2:2888:3888

3.zookeeper 的目录下 新建 data目录 并在data目录下 创建myid文件
	1.mkdir data
	2.cd /data  vi myid  1

4.节点分发
	scp -r /opt/module/zookeeper slave1:/opt/module/
	scp -r /opt/module/zookeeper slave2:/opt/module/
	
5.修改slave1 | slave2 节点的myid文件
	slave1:2
	slave2:3

6.启动zookeeper
	启动：zkServer.sh start 
	状态：zkServer.sh stop
```



##### 七、KAFKA集群配置

```
1.配置kafka环境变量 -- 环境变量失效解决办法
	export PATH=/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:/bin:/sbin:/root/bin

2.source 环境变量
	source /etc/profile
	
3.配置server.property
	broker.id=1
	host.name=192.168.43.191
	listeners=PLAINTEXT://0.0.0.0:9092
	advertised.host.name=主机名
	advertised.listeners=PLAINTEXT:本机ip：9092
	修改logs路径
	修改zookeeper路径
	
4.节点分发
	scp -r /opt/module/kafka slave1:/opt/module/
	scp -r /opt/module/kafka slave2:/opt/module/

5. slave1 | slave2 修改server.property

6.启动kafka
	kafka-server-start.sh -daemon /opt/module/kafka/conf/server.property 

7.查看主题
	kafka-topic.sh --list --bootstrap-server master:9092
	
8.创建主题
	kafka.topic.sh --create --bootstrap-server master:9092 --replication-factor 1  --partitions 2 --topic zhang

9.开启kafka生产者
	kafka-console-produce.sh --broker-list master:9092 --topic zhang
	
10.开启kafka 消费者
	kafka-console-consumer.sh --bootstrap-server master:9092 --topic zhang --from-beginning
```



##### 八、FLUME 单机配置

```
1.配置环境变量
	export FLUME_HOME=/opt/module/flume
	export PATH=$PATH:$FLUME_HOME/bin
	
2.环境变量失效解决办法
	export PATH=/usr/bin:/usr/sbin:/bin:/sbin:/usr/local/bin:/usr/local/sbin:/root/bin
	
3.soure 环境变量
	source /etc/profile

4. 在conf目录下 自定义文件 ： jiaoben.conf
	a1.sources=r1
	a1.channels=c1
	a1.sinks=k1
	
	a1.sources.r1.type=netcat
	a1.sources.r1.bind=localhost
	a1.sources.r1.port=25001
	
	a1.channels.c1.type=memory
	
	a1.sinks.k1.type=org.apache.flume.sink.kafka.KafkaSink
	a1.sinks.k1.brokerList=master:9092,slave1:9092,slave2:9092
	a1.sinks.k1.topic=odb_mall_log
	
	a1.sources.r1.channels=c1
	a1.sinks.k1.channel=c1
	
5.启动flume
	flume-ng agent -c conf -f /opt/module/flume/conf/jiaoben.conf --name a1 -Dflume.root.logger=INFO,console
```



##### 九、HBASE集群配置

```xml
1.配置环境变量
	export HBASE_HOME=/opt/module/hbase
	export PATH=$PAHT:$HBASE_HOME/bin

2.source 环境变量
	source /etc/profile

3.配置 hbase.env.sh
	1.设置jdk路径
	2.不适用外部hbase | 126行
	3.hadoop关联     | 135行

4.hbase-site.xml
	# 使用外部分布式hbase
	<property>
		<name>hbase.cluster.distributed</name>
        <value>true</value>
	</property>

	# 使用外部zookeeper
	<property>
		<name>hbase.zookeeper.quorum</name>
        <value>master,slave1,slave2</value>
	</property>

	# 确定zooKeeper datadir 位置
	<property>
		<name>hbase.zookeeper.property.dataDir</name>
        <value>/opt/module/zookeeper/data</value>
	</property>

	# hbase root 目录
	<property>
		<name>hbase.rootdir</name>
        <value>hdfs://master:9000/hbase</value>
	</property>

	# 关闭hbase 安全模式
	<property>
		<name>hbase.unsafe.stream.capability.enforce</name>
        <value>false</value>
	</property>

5. reg……
	master
	slave1
	slave2

6.启动hbase 
	./start-hbase.sh

7.进入hbase shell
	查看命名空间：list_namespace
```



##### 十、MAXWELL 集群配置

```
1.配置环境变量
	export MAXWELL_HOME=/opt/module/maxwell
	export PATH=$PATH:$MAXWELL_HOME/bin
	
2.source 环境变量
	source /etc/profile
	
3.往 /etc/my.cnf 中加入配置 -- 前提是有mysql
	数据库id
	server-id= 随便写
	
	启动binlong，改参数的值会作为binlog的文件名
	log-bin=mysql-bin
	
	binlong类型，maxwell要求为row类型
	binlog_format=row
	
	需要监控的数据库的名字
	binlog-do-db=
	
4.配置完毕后 需要重启mysql
	service mysql restart 
	
5.配置confi.property
	produce=kafka
	kafka.bootstrap.servers=master,slave1,slave2
	kafka_topic=ods_mall_log
	host=localhost
	user=root
	password=123456

6.启动maxwell
	maxwell --config /opt/module/maxwell/conf/config.properties -daemon
	
```



##### 十一、配合CLICKHOUSE 单机

```
1.	解压4个clickhouse安装包到指定位置
	tar -zxvf clickhouse-common-static-21.9.4.35.tgz -C /usr/local/src/clickhouse/
	tar -zxvf clickhouse-common-static-dbg-21.9.4.35.tgz -C /usr/local/src/clickhouse/
	tar -zxvf clickhouse-client-21.9.4.35.tgz -C /usr/local/src/clickhouse/
	tar -zxvf clickhouse-server-21.9.4.35.tgz -C /usr/local/src/clickhouse/
	
2.	进入各个目录下 执行/install/doinst.sh  -- 可以不用管执行顺序
	clickhouse-common-static-21.9.4.35/install/doinst.sh
	clickhouse-common-static-dbg-21.9.4.35/install/doinst.sh
	clickhouse-client-21.9.4.35/install/doinst.sh
	clickhouse-server-21.9.4.35/install/doinst.sh
	在安装clickhouse-server的时候会提示输入默认账户的user密码和是否运行远程访问
	
3.删除 /etc/clickhouse-server/conf.d/ 目录下面的文件

4.给cliskhouse 授权  var 两个 etc 两个
	chown -R root:root /var/lib/clickhouse /var/log/clickhouse-server /etc/clickhouse-server /etc/clickhouse-click
	
5.修改配置文件 /etc/clickhouse-server/config.xml
	1.修改：listen_host == 127.0.0.0
	2.修改时区： timezone == Asia/Shanghai   Asia == 亚洲
	3.替换： 把所有的9000 端口 替换为 9001 或其他  替换命令：%s /9000/9001

6.启动clickhouse 
	clickhouse-server --config-file=/etc/clickhouse-server/config.xml -daemon
	
7.连接clickhouse
	clickhouse-click --port 9001 --password  -- 安装的时候设置的密码
	
```





