### 8月28日总结

<hr>



#### 一、HBASE 集群搭建  -- ZOOKEEPER -- Hadoop 启动

```xml
1.核心配置
	hbase-env.sh
		1.配置jdk
		2.禁用内部hbase
	
	hbase-site.xml
		#使用分布式hbase集群
		<property>
			<name>hbase.cluster.distributed</name>
            <value>true</value>
		</property>

		#确定ZOOKEEPER地址
		<property>
			<name>hbase.zookeeper.quorum</name>
            <value>master:2181,slave1:2181,slave2:2181</value>
		</property>

		#hbase 存放目录
		<property>
			<name>hbase.rootdir</name>
            <value>hdfs://master:9000/hbase</value>
		</property>

		#关闭hbas安全模式
		<property>
			<name>hbase.unsafe.stream.capability.enforce</name>
            <value>false</value>
		</property>

		#确定ZOOKEEPER 属性的datadir目录
		<property>
			<name>hbase.zookeeper.property.dataDir</name>
            <value>/usr/local/src/zookeeper/data</value>
		</property>
```





#### 二、CLICKHOIUSE单机版安装

``` 
1.进入文件指定目录，执行doinst.sh 
   ./clickhouse-xxxx/install/doinst.sh
   ./clickhouse-xxxx/install/doinst.sh
   ./clickhouse-xxxx/install/doinst.sh
   ./clickhouse-sever/install/doinst.sh -- 需要输入密码 
   
2.删除 /etc/clickhouse-server/config.d/listen.xml 文件


3.设置root权限  var(log  lib)  etc(server,click)
	chown -R root:root /var/lib/clickhouse /var/log/clickhouse-server  /etc/clickhouse-click/ /etc/clickhouse-sever/
   
4. 进入 /etc/clickhouse-server/conf.xml
	(1):修改 listen
		取消：listen_host 注释  ---> 如果启动报错： 就改为 127.0.0.1
		
	(2):修改时区
		timezone == Asia/Shanghai   = Asia == 亚洲
		
	(3):修改端口号
		替换： %s/9000/90001
5.启动clickhouse
	clickhouse-server --config-file=/etc/clickhouse-server/config.xml

6.连接本机的clickhouse
	clickhouse=client --port 9000(填修改后的端口) -- password 123456
```





### 三、 kafka  命令优化

```
kafka:
	查看主题：
		(优化前)
		kafka-topic.sh --list --zookeeper master:2181 
		(优化后)-- 兼容比赛
		kafka.topic.sh --list --bootstrap-server master:9092
	创建主题：
		(优化前)
		kafka-topic.sh --create --zookeeper master:2181  --replication-factor 1 --partitions 1 --topic zhang
		(优化后)-- 兼容比赛
		kafka.topic.sh --create  --bootstrap-server master:9092 --replication-factor 1 --partitions 1 --topic zhang
```





#### 四、flume 采集端口到kafka

```
主要配置：
	a1.sources=r1
	a1.channels=c1
	a1.sinks=k1
	
	a1.sources.r1.type=netcat
	a1.sources.r1.bind=master | ip
	a1.sources.r1.port=12005
	
	a1.channels.c1.type=memory
	
	a1.sinks.k1.type=org.apache.flume.sink.kafka.KafkaSink
	a1.sinks.k1.brokerList=maste:9092,slave1:9092,slave2:9092
	a1.sinks.k1.topic=zhang
	
	a1.sources.r1.channels=c1
	a1.sinks.k1.channel=c1
	
启动flume
	flume-ng agent	-c conf -f/opt/module/flume/conf/duankou.conf --name a1 -Dflume.root.logger=INFO,console

```





